{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Importing liblaries for the algorithm","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # for plotting features\n\nfrom skimage.feature import hog #importing hog feature\nfrom skimage import data, feature, exposure\nimport cv2 #to read and modify images","metadata":{"execution":{"iopub.status.busy":"2022-05-03T20:46:05.937812Z","iopub.execute_input":"2022-05-03T20:46:05.938142Z","iopub.status.idle":"2022-05-03T20:46:05.946652Z","shell.execute_reply.started":"2022-05-03T20:46:05.938110Z","shell.execute_reply":"2022-05-03T20:46:05.945751Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"Plotting an image sample using hog feature in the images","metadata":{}},{"cell_type":"code","source":"image = cv2.imread('../input/celeba-dataset/img_align_celeba/img_align_celeba/000001.jpg')\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nfd, hog_image = hog(image, orientations=8, pixels_per_cell=(16, 16),\n                    cells_per_block=(1, 1), visualize=True, multichannel=True)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6), sharex=True, sharey=True)\n\nax1.axis('off')\nax1.imshow(image, cmap=plt.cm.gray)\nax1.set_title('Input image')\n\n# Rescale histogram for better display\nhog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n\nax2.axis('off')\nax2.imshow(hog_image_rescaled, cmap=plt.cm.gray)\nax2.set_title('Histogram of Oriented Gradients')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-03T20:46:14.908251Z","iopub.execute_input":"2022-05-03T20:46:14.908738Z","iopub.status.idle":"2022-05-03T20:46:15.291725Z","shell.execute_reply.started":"2022-05-03T20:46:14.908690Z","shell.execute_reply":"2022-05-03T20:46:15.290959Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"extracting data","metadata":{}},{"cell_type":"code","source":"#importing data_attribute\ndata_atr = pd.read_csv(\"../input/celeba-dataset/list_attr_celeba.csv\",index_col=\"image_id\")\ndata_atr.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-03T20:46:28.164351Z","iopub.execute_input":"2022-05-03T20:46:28.164668Z","iopub.status.idle":"2022-05-03T20:46:29.044295Z","shell.execute_reply.started":"2022-05-03T20:46:28.164634Z","shell.execute_reply":"2022-05-03T20:46:29.043479Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"data cleaning","metadata":{}},{"cell_type":"code","source":"#clean data\ndata_atr.replace(to_replace=-1, value=0, inplace=True)\ndata_atr.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-03T20:46:47.926796Z","iopub.execute_input":"2022-05-03T20:46:47.927079Z","iopub.status.idle":"2022-05-03T20:46:47.979115Z","shell.execute_reply.started":"2022-05-03T20:46:47.927048Z","shell.execute_reply":"2022-05-03T20:46:47.978109Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"If NaN is present, fill it with a 0","metadata":{}},{"cell_type":"code","source":"#if NaN present fill a 0\ndata_atr = data_atr.fillna('0')\ndata_atr.info()","metadata":{"execution":{"iopub.status.busy":"2022-05-03T20:47:04.626097Z","iopub.execute_input":"2022-05-03T20:47:04.627038Z","iopub.status.idle":"2022-05-03T20:47:04.668344Z","shell.execute_reply.started":"2022-05-03T20:47:04.626986Z","shell.execute_reply":"2022-05-03T20:47:04.667669Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"getting columns of attributes","metadata":{}},{"cell_type":"code","source":"#columns\nprint(\"ATTRIBUTES\")\nnUm = 1\nfor col in data_atr.columns:\n    print(f\"ATTRIBUTE {nUm} : {col}\")\n    nUm += 1","metadata":{"execution":{"iopub.status.busy":"2022-05-03T20:47:28.186585Z","iopub.execute_input":"2022-05-03T20:47:28.187343Z","iopub.status.idle":"2022-05-03T20:47:28.196752Z","shell.execute_reply.started":"2022-05-03T20:47:28.187298Z","shell.execute_reply":"2022-05-03T20:47:28.195754Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"extracting Male attribute column","metadata":{}},{"cell_type":"code","source":"#identify gender using male column\ngender = data_atr['Male']\ngender.head(6)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T20:47:44.542791Z","iopub.execute_input":"2022-05-03T20:47:44.543090Z","iopub.status.idle":"2022-05-03T20:47:44.553343Z","shell.execute_reply.started":"2022-05-03T20:47:44.543055Z","shell.execute_reply":"2022-05-03T20:47:44.552011Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"Plotting a graph of gender distribution in the dataset","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\n# Gender distribution\nplt.title('Gender Distribution')\nsns.countplot(y = 'Male', data=data_atr)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-03T20:47:57.784926Z","iopub.execute_input":"2022-05-03T20:47:57.785224Z","iopub.status.idle":"2022-05-03T20:47:58.016560Z","shell.execute_reply.started":"2022-05-03T20:47:57.785196Z","shell.execute_reply":"2022-05-03T20:47:58.015653Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"extracting all, men and women image samples from the dataset and source","metadata":{}},{"cell_type":"code","source":"#load image id's with men and women attribute and fix them to an array\nfrom keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n\nimg_path = '../input/celeba-dataset/img_align_celeba/img_align_celeba/'\nMen = data_atr.loc[data_atr['Male']==1]\nmen =Men.iloc[0:1000, : ]\nmt = Men.iloc[100:2000, : ]\nWomen = data_atr.loc[data_atr['Male']==0]\nwomen = Women.iloc[0:1000, : ]\nwt = Women.iloc[100:2000, : ]\nwt_i = np.array(wt.index)\nmt_i = np.array(mt.index)\nwomen_i = np.array(women.index) #holds women image names\nmen_i = np.array(men.index) # holds men image names\nmen_images = []\nmt_images = []\nwt_images =[]\nwomen_images = []\nfor im in women_i:\n    image = cv2.imread('../input/celeba-dataset/img_align_celeba/img_align_celeba/'+im)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    women_images.append(image)\n    image = np.expand_dims(image, axis =0)\nfor im in men_i:\n    image = cv2.imread('../input/celeba-dataset/img_align_celeba/img_align_celeba/'+im)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    men_images.append(image)\n    image = np.expand_dims(image, axis =0)\nfor im in wt_i:\n    image = cv2.imread('../input/celeba-dataset/img_align_celeba/img_align_celeba/'+im)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    wt_images.append(image)\nfor im in mt_i:\n    image = cv2.imread('../input/celeba-dataset/img_align_celeba/img_align_celeba/'+im)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    mt_images.append(image)\n#all images\nall_im = data_atr\nim_all =all_im.iloc[1000:2000, : ]\nall_i = np.array(im_all.index)\nim_All = []\nfor im in all_i:\n    image = cv2.imread('../input/celeba-dataset/img_align_celeba/img_align_celeba/'+im)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    im_All.append(image)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T20:49:21.238988Z","iopub.execute_input":"2022-05-03T20:49:21.239283Z","iopub.status.idle":"2022-05-03T20:49:49.148879Z","shell.execute_reply.started":"2022-05-03T20:49:21.239254Z","shell.execute_reply":"2022-05-03T20:49:49.147858Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"Training ","metadata":{}},{"cell_type":"code","source":"from itertools import chain\nX_train = np.array([feature.hog(im,channel_axis=-1)\n                    for im in chain(men_images,\n                                    women_images)])\ny_train = np.zeros(X_train.shape[0])\ny_train[:(np.array(men_images)).shape[0]] = 1","metadata":{"execution":{"iopub.status.busy":"2022-05-03T20:50:00.096486Z","iopub.execute_input":"2022-05-03T20:50:00.096842Z","iopub.status.idle":"2022-05-03T20:50:45.437924Z","shell.execute_reply.started":"2022-05-03T20:50:00.096807Z","shell.execute_reply":"2022-05-03T20:50:45.436966Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"y_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-03T20:50:53.798388Z","iopub.execute_input":"2022-05-03T20:50:53.798721Z","iopub.status.idle":"2022-05-03T20:50:53.804853Z","shell.execute_reply.started":"2022-05-03T20:50:53.798688Z","shell.execute_reply":"2022-05-03T20:50:53.803883Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"Training process","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import cross_val_score\n\ncross_val_score(GaussianNB(), X_train, y_train)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-03T20:51:02.567726Z","iopub.execute_input":"2022-05-03T20:51:02.568620Z","iopub.status.idle":"2022-05-03T20:51:08.545599Z","shell.execute_reply.started":"2022-05-03T20:51:02.568573Z","shell.execute_reply":"2022-05-03T20:51:08.544874Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"Getting the accuracy in percentage","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import LinearSVC\nfrom sklearn.model_selection import GridSearchCV\ngrid = GridSearchCV(LinearSVC(), {'C': [1.0, 2.0, 4.0, 8.0]})\ngrid.fit(X_train, y_train)\nprint(\"ACCURACY: \",(grid.best_score_)*100,\" %\")\n","metadata":{"execution":{"iopub.status.busy":"2022-05-03T21:28:25.437445Z","iopub.execute_input":"2022-05-03T21:28:25.438258Z","iopub.status.idle":"2022-05-03T21:29:42.766358Z","shell.execute_reply.started":"2022-05-03T21:28:25.438219Z","shell.execute_reply":"2022-05-03T21:29:42.765349Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"Getting the best model","metadata":{}},{"cell_type":"code","source":"grid.best_params_","metadata":{"execution":{"iopub.status.busy":"2022-05-03T20:54:38.579956Z","iopub.execute_input":"2022-05-03T20:54:38.580962Z","iopub.status.idle":"2022-05-03T20:54:38.586650Z","shell.execute_reply.started":"2022-05-03T20:54:38.580909Z","shell.execute_reply":"2022-05-03T20:54:38.585717Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"Training the model again using the best model found above ","metadata":{}},{"cell_type":"code","source":"#retraining the whole algorithm using the best estimator\nmodel = grid.best_estimator_\nmodel.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T20:54:49.875362Z","iopub.execute_input":"2022-05-03T20:54:49.875673Z","iopub.status.idle":"2022-05-03T20:55:00.684568Z","shell.execute_reply.started":"2022-05-03T20:54:49.875643Z","shell.execute_reply":"2022-05-03T20:55:00.683590Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"Defining elements that will make us know when the algorithm is full functioning","metadata":{}},{"cell_type":"code","source":"X_predict = np.array([feature.hog(im,channel_axis=-1)\n                    for im in im_All])","metadata":{"execution":{"iopub.status.busy":"2022-05-03T20:55:15.463540Z","iopub.execute_input":"2022-05-03T20:55:15.464379Z","iopub.status.idle":"2022-05-03T20:55:38.163906Z","shell.execute_reply.started":"2022-05-03T20:55:15.464326Z","shell.execute_reply":"2022-05-03T20:55:38.162833Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"Importing important liblaries for another section of training\nReplacing 0 with Woman and 1 with Man in gender set","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nX = np.array([feature.hog(im,channel_axis=-1)\n                    for im in im_All ])\n#clean data\ngender.replace(to_replace=0, value=\"Female\", inplace=True)\ngender.replace(to_replace=1, value=\"Male\", inplace=True)\ny = gender.iloc[1000:2000] #taking gender variables for each image\ngender.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-03T20:56:06.253320Z","iopub.execute_input":"2022-05-03T20:56:06.253984Z","iopub.status.idle":"2022-05-03T20:56:29.157289Z","shell.execute_reply.started":"2022-05-03T20:56:06.253946Z","shell.execute_reply":"2022-05-03T20:56:29.156428Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"Training and Testing session using LogisticRegression model","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)   \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\n#Model Building using logosticRegression\nlogit = make_pipeline(StandardScaler(), LogisticRegression())#removes default iteration number set\n#Fitting algorithm\n#X_test.reshape(1,-1)\n#y_test.reshape(1,-1)\nlogit.fit(X_train, y_train)\n#Calculating the acuracy\nprint(\"Accuracy \",(logit.score(X_test,y_test))*100,\"%\")\n#y_test","metadata":{"execution":{"iopub.status.busy":"2022-05-03T21:02:49.749348Z","iopub.execute_input":"2022-05-03T21:02:49.749674Z","iopub.status.idle":"2022-05-03T21:02:54.556866Z","shell.execute_reply.started":"2022-05-03T21:02:49.749645Z","shell.execute_reply":"2022-05-03T21:02:54.555849Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"Using the images array defined earlier we can predict the gender of each element using the algorithm","metadata":{}},{"cell_type":"code","source":"New_predict = logit.predict(X_predict)\nprint(New_predict)","metadata":{"execution":{"iopub.status.busy":"2022-05-03T21:03:54.367046Z","iopub.execute_input":"2022-05-03T21:03:54.367430Z","iopub.status.idle":"2022-05-03T21:03:54.659461Z","shell.execute_reply.started":"2022-05-03T21:03:54.367395Z","shell.execute_reply":"2022-05-03T21:03:54.655995Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"Here the model accepts user inputs so that the gender can be predicted using the machine learning algorithm\nMake sure the file path is correct","metadata":{}},{"cell_type":"code","source":"#allowing user inputs \ntimage = cv2.imread('../input/celeba-dataset/img_align_celeba/img_align_celeba/040001.jpg')#change the filename to a desired one\ntimage = cv2.cvtColor(timage, cv2.COLOR_BGR2RGB)\nfd, hog_image = hog(timage, orientations=8, pixels_per_cell=(16, 16),\n                    cells_per_block=(1, 1), visualize=True, multichannel=True)\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6), sharex=True, sharey=True)\n\nax1.axis('off')\nax1.imshow(timage, cmap=plt.cm.gray)\nax1.set_title('Input image')\n\n# Rescale histogram for better display\nhog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n\nax2.axis('off')\nax2.imshow(hog_image_rescaled, cmap=plt.cm.gray)\nax2.set_title('Histogram of Oriented Gradients')\nplt.show()\nX_predict = np.array([feature.hog(timage,channel_axis=-1)])#defining the test image as the predict\nNew_predict = logit.predict(X_predict)\nprint(f'prediction: {New_predict} ')","metadata":{"execution":{"iopub.status.busy":"2022-05-03T21:40:41.192733Z","iopub.execute_input":"2022-05-03T21:40:41.193172Z","iopub.status.idle":"2022-05-03T21:40:41.488215Z","shell.execute_reply.started":"2022-05-03T21:40:41.193140Z","shell.execute_reply":"2022-05-03T21:40:41.487187Z"},"trusted":true},"execution_count":51,"outputs":[]}]}